# Reinforcement Learning Resource with Manipulation

**Practical Reinforcement Learning and Robotics**

This is a resource collection focusing on reinforcement learning and manipulation. As we all known, it's hard for beginner in robotics and reinforcement learning. My work is manipulation and reinforcement learning, so I try to collect some useful resource about it, mainly for the code in practice.

__*Talk is cheap. Show me the code. --- Linus Torvalds*__

# Table of Contents

[TOC]

## Overview
	- [Code](#code)
	- [code](#reinforcement-learning-framework)

# Manipulation and Grasping with Deep Reinforcement Learning

## Code

- [Stochastic Latent Actor-Critic](https://github.com/alexlee-gk/slac)

Code will be released soon.

Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model https://alexlee-gk.github.io/slac/


- []()

- []()

- []()

- []()

## Paper




# Useful things for my works

-[Setting  up  a  Reinforcement  Learning  Task  with  a  Real-World  Robot](https://arxiv.org/pdf/1803.07067.pdf)

How to set up a RL task with UR5 robot

- [Benchmarking Reinforcement Learning Algorithmson Real-World Robots](https://arxiv.org/pdf/1809.07731.pdf)

Using UR5 robot in RL. Source code for all tasks available at https://github.com/kindredresearch/SenseAct

- [Learning how to Grasp Objects with Robotic Gripper using Deep Reinforcement Learning](https://www.doc.ic.ac.uk/~ejohns/Documents/jiaxi_liu_thesis.pdf)

This is a master degree from Imperial College London.

- [CASSL: Curriculum Acceleratd Self-Supervised Learning](https://arxiv.org/pdf/1708.01354.pdf)

A paper using Robotiq 3 finger gripper.

# Awesome Reinforcement Learning

- https://github.com/aikorea/awesome-rl
- https://github.com/tigerneil/awesome-deep-rl
- https://github.com/dbobrenko/awesome-rl
- https://github.com/brianspiering/awesome-deep-rl
- https://github.com/wwxFromTju/awesome-reinforcement-learning-zh

# Paper List

- [Deep-Learning-Papers-Reading-Roadmap](https://github.com/floodsung/Deep-Learning-Papers-Reading-Roadmap)

Deep Learning papers reading roadmap for anyone who are eager to learn this amazing tech!

- [Meta-Learning-Papers](https://github.com/floodsung/Meta-Learning-Papers)

Meta Learning / Learning to Learn / One Shot Learning / Few Shot Learning

- [Life-Learning-Paper-List](https://github.com/floodsung/Lifelong-Learning-Paper-List)

Lifelong/Continual Learning Paper List

# Reinforcement Learning Course

- [Deep_reinforcement_learning_Course](https://github.com/simoninithomas/Deep_reinforcement_learning_Course)

Implementations from the free course Deep Reinforcement Learning with Tensorflow

- [reinforcement learning practice](https://github.com/dennybritz/reinforcement-learning)

Implementation of Reinforcment Learning Algorithms. Python, OpenAI Gym, Tensorflow. Exercises and Solutions to accompany Sutton's Book and David Silver's course.

- [morvanzhou python](https://morvanzhou.github.io/)

A good tutorial to learn the python, machine learning, deep learning, reinforcement learning.

- [Sutton's Reinforcement Learning Chinese]( https://github.com/qiwihui/reinforcement-learning-an-introduction-chinese)

- [reinforcement learning introduction](https://github.com/qqiang00/reinforce)

A good introduction and tutorial of reinforcement learning

- [basic_reinforcement_learning](https://github.com/vmayoral/basic_reinforcement_learning)

An introductory series to Reinforcement Learning (RL) with comprehensive step-by-step tutorials.

- [David-Silver-Reinforcement-learning](https://github.com/dalmia/David-Silver-Reinforcement-learning)

Notes for the Reinforcement Learning course by David Silver along with implementation of various algorithms.

- [100-Days-Of-ML-Code](https://github.com/MLEveryday/100-Days-Of-ML-Code)

- [pumpkin-book](https://github.com/datawhalechina/pumpkin-book)

- [DRL-debug-tips](https://zhuanlan.zhihu.com/p/31810802)

南瓜书PumpkinBook
https://datawhalechina.github.io/pumpkin-book

- [强化学习路在何方？](https://zhuanlan.zhihu.com/p/39999667)

- [Deep Reinforcement Learning Doesn't Work Yet](https://www.alexirpan.com/2018/02/14/rl-hard.html)

- [[Model-based]基于模型的强化学习论文合集](https://zhuanlan.zhihu.com/p/72642285)

- [前沿强化学习问题](https://zhuanlan.zhihu.com/p/47602043)

- [强化学习资料](https://zhuanlan.zhihu.com/p/77123184)

- [good blog](https://blog.csdn.net/jinzhuojun?t=1)

- [RL-noise](https://zhuanlan.zhihu.com/p/78601257)

- [RL-interview](https://zhuanlan.zhihu.com/p/33133828)

# Reinforcement Learning Framework

- [OpenAI gym](https://gym.openai.com/)

A toolkit for developint and comparing reinforcement learning algorithms.

- [deepmind dm_control](https://github.com/deepmind/dm_control)

The DM Control Suite and Package is a tool for developing and testing reinforcement learning agents for the MuJoCo physics engine.

- [garage](https://github.com/rlworkgroup/garage)

A toolkit for reproducible reinforcement learning research.

[Document](https://garage.readthedocs.org/en/latest/)

- [rllab](https://github.com/rll/rllab)

rllab is a framework for developing and evaluating reinforcement learning algorithms, fully compatible with OpenAI Gym. Now maintains it under the name [garage](https://github.com/rlworkgroup/garage)

[rllab document](https://rllab.readthedocs.org/en/latest/)


- [Horizon](https://github.com/facebookresearch/Horizon)

A platform for Applied Reinforcement Learning (Applied RL), developed by Facebook. https://horizonrl.com



- [PyRobot]()

[PyRobot: An Open-source Robotics Framework for Research and Benchmarking](https://arxiv.org/pdf/1906.08236.pdf)


- [Tensor2Robot](https://github.com/google-research/tensor2robot) ([Google-AI-Robotics](https://ai.google/research/teams/brain/robotics/))

This repository contains distributed machine learning and reinforcement learning infrastructure.

It is used internally at Alphabet, and open-sourced with the intention of making research at Robotics @ Google more reproducible for the broader robotics and computer vision communities. 



- [pyrobolearn](https://github.com/robotlearn/pyrobolearn)

This repository contains the code for the PyRoboLearn (PRL) framework: a Python framework for Robot Learning. This framework revolves mainly around 7 axes: simulators, worlds, robots, interfaces, learning tasks (= environment and policy), learning models, and learning algorithms.

Currently, we mainly use the PyBullet simulator.

It includes a lot of robot environment. [Robot Env List](https://github.com/robotlearn/pyrobolearn/tree/master/pyrobolearn/robots)

- [bsuite](https://github.com/deepmind/bsuite)

bsuite is a collection of carefully-designed experiments that investigate core capabilities of a reinforcement learning (RL) agent with two main objectives.

To collect clear, informative and scalable problems that capture key issues in the design of efficient and general learning algorithms.
To study agent behavior through their performance on these shared benchmarks.
This library automates evaluation and analysis of any agent on these benchmarks. It serves to facilitate reproducible, and accessible, research on the core issues in RL, and ultimately the design of superior learning algorithms.

Going forward, we hope to incorporate more excellent experiments from the research community, and commit to a periodic review of the experiments from a committee of prominent researchers.

- [TRFL](https://github.com/deepmind/trfl/)

TRFL (TensorFlow Reinforcement Learning, pronounced "truffle") is a library built on top of Tensorflow that exposes several useful building blocks for implementing Reinforcement Learning agents.

Developed by DeepMind.

- [Dopamine](https://github.com/google/dopamine)

Dopamine is a research framework for fast prototyping of reinforcement learning algorithms, developed by Google.


# Reinforcement Learning Simulation

Introduce some useful simulators.

[Tools for dynamics simulation of robots: a survey based on user feedback](https://arxiv.org/pdf/1402.7050.pdf)

## [SimBenchmark](https://leggedrobotics.github.io/SimBenchmark/)

Physics engine benchmark for robotics applications: RaiSim vs. Bullet vs. ODE vs. MuJoCo vs. DartSim

SimBenchmark provides benchmark results of contact simulation on the state-of-the-art physics engines for various robotic tasks.

## Mujoco

The most popular simulator in reinforcement learning research, although it's not free.

- [Mujoco](http://www.mujoco.org/)

Offical webset, including the installation, documentation, forum, and some other useful resources.

- [Mujoco_py](https://github.com/openai/mujoco-py)

MuJoCo is a pyhsics engine for detailed, efficient rigid body simulations with contacts. mujoco_py allows using MuJoCo from Python 3.

- [Mujoco-Unity-Plugin](https://github.com/PSVL/Mujoco-Unity-Plugin)

Open source Mujoco Unity plugin for Doorgym project

- [Mujoco_ros_pkgs](https://github.com/shadow-robot/mujoco_ros_pkgs)
  
ROS integration of Mujoco simulator, developed by Shadow Robot.

- [openai-orrb](https://github.com/openai/orrb)

We present the OpenAI Remote Rendering Backend (ORRB), a system that allows fast  and customizable rendering  of robotics  environments.   It is based  on the Unity3d game engine and interfaces with the MuJoCo physics simulation library.  ORRB was designed with visual domain randomization in mind.  It is optimized for cloud deployment and high throughput operation. 



## Bullet

- [bullet3](http://bulletphysics.org)

Bullet Physics SDK: real-time collision detection and multi-physics simulation for VR, games, visual effects, robotics, machine learning etc.

- [pybullet-gym](https://github.com/benelot/pybullet-gym)

PyBullet Gymperium is an open-source implementation of the OpenAI Gym MuJoCo environments for use with the OpenAI Gym Reinforcement Learning Research Platform in support of open research.

(https://github.com/bulletphysics/bullet3)

## Gazebo

Using Gazebo to train the RL agent.

#### Gym-Gazebo

[Robot_gym](https://arxiv.org/abs/1808.10369)

[Accelerated robot training through simulation in the cloud with ROS and Gazebo](https://medium.com/@vmayoral/accelerated-robot-training-through-simulation-in-the-cloud-with-ros-and-gazebo-bac6bc493520)

Code:

[gym-gazebo](https://github.com/erlerobot/gym-gazebo/)

[gym-gazebo2](https://github.com/AcutronicRobotics/gym-gazebo2)

## Unity

Unity is another open source reinforcement learning environment, has good render.

- [Unity-al-agent-toolkit](https://github.com/Unity-Technologies/ml-agents)

The Unity Machine Learning Agents Toolkit (ML-Agents) is an open-source Unity plugin that enables games and simulations to serve as environments for training intelligent agents. Agents can be trained using reinforcement learning, imitation learning, neuroevolution, or other machine learning methods through a simple-to-use Python API. We also provide implementations (based on TensorFlow) of state-of-the-art algorithms to enable game developers and hobbyists to easily train intelligent agents for 2D, 3D and VR/AR games. These trained agents can be used for multiple purposes, including controlling NPC behavior (in a variety of settings such as multi-agent and adversarial), automated testing of game builds and evaluating different game design decisions pre-release. The ML-Agents toolkit is mutually beneficial for both game developers and AI researchers as it provides a central platform where advances in AI can be evaluated on Unity’s rich environments and then made accessible to the wider research and game developer communities.

## [V-REP](http://www.coppeliarobotics.com/index.html)

[PyRep](https://github.com/stepjam/PyRep) is a toolkit for robot learning research, build on top of the virtual robotics experimentation platform.

## [Raisim](https://github.com/leggedrobotics/raisimLib)

Raisim is a physics engine for rigid-body dynamics simulation. Although it is a general physics engine, it has been mainly used/tested for robotics and reinforcement learning so far. It features an efficient implementation of recursive algorithms for articulated system dynamics (Recursive Newton-Euler and Composite Rigid Body Algorithm). RaisimLib is an exported cmake package of raisim.

Developed by Robotic Systems Lab, ETH Zurich.

- [SimBenchmark](https://leggedrobotics.github.io/SimBenchmark/): Physics engine benchmark for robotics applications: RaiSim vs. Bullet vs. ODE vs. MuJoCo vs. DartSim
- [raisimOgre](https://github.com/leggedrobotics/raisimOgre): Visualizer for raisim. It is a simple wrapper around Ogre3d(https://www.ogre3d.org/), which is an open-source 3d rendering library.
- [raisimGym](https://github.com/leggedrobotics/raisimGym): a few gym environments using RAISIM
- [raisimPy](https://github.com/robotlearn/raisimpy): a (third-party) python wrapper of RAISIM

## [DeepMind Lab](https://github.com/deepmind/lab)

DeepMind Lab is a 3D learning environment based on id Software's Quake III Arena via ioquake3 and other open source software.

DeepMind Lab provides a suite of challenging 3D navigation and puzzle-solving tasks for learning agents. Its primary purpose is to act as a testbed for research in artificial intelligence, especially deep reinforcement learning.

## [spriteworld](https://github.com/deepmind/spriteworld)

Spriteworld is a python-based RL environment that consists of a 2-dimensional arena with simple shapes that can be moved freely. 

# Reinforcement Learning Code

## gym environment

- [Contimuouscontrol](https://github.com/Jialn/ContinuousControl)

Some continuous control experiemnts based on OpenAI baselines, Gym, and Mujoco. 

Including:
7bot arm physical robot reach problem; 
Ping-pong Game in mujoco; 
Spider/Humanoid robot walking. 

- [cassie-mujoco-sim](https://github.com/osudrl/cassie-mujoco-sim)

A simulation library for Agility Robotics' Cassie robot using MuJoCo

- [cassie-trajectory-editor](https://github.com/osudrl/cassie-trajectory-editor)

MuJoCo trajectory editor for walking robots

- [gym-cassie](https://github.com/p-morais/gym-cassie)

An OpenAI Gym style reinforcement learning interface for Agility Robotics' biped robot Cassie

- [Cassie-Robot-Resources](https://github.com/UBCMOCCA/Cassie_Robot_Resources)


list of papers, videos and codes about the bipedal robot Cassie developed by Agility Robotics

- [marathon-envs](https://github.com/Unity-Technologies/marathon-envs)

A set of high-dimensional continuous control environments for use with Unity ML-Agents Toolkit.

- [gym-kuka-mujoco](https://github.com/HarvardAgileRoboticsLab/gym-kuka-mujoco)

An OpenAI gym environment for the Kuka arm, using Mujoco simulator.

- [Kuka-bullet-for-pick-and-place](https://github.com/cb614611757/Kuka_Pybullet-for-pick-and-place)

Kuka_Pybullet for pick and place This script can be used for the research of robotic reinforcement learning. The script builds a simulation environment for robot manipulation about pick and place based on the pybullet simulation environment. Users can incorporate this environment into the reinforcement learning algorithm for online data collec… 

- [pybullet-robot-envs](https://github.com/robotology-playground/pybullet-robot-envs)

pybullet-robot-envs is a Python package that collects robotic environments based on the **PyBullet** simulator, suitable to develop and test Reinforcement Learning algorithms on simulated **grasping** and **manipulation** applications.

The pybullet-robot-envs inherit from the **OpenAI Gym** interface.

The package provides environments for the **iCub Humanoid robot** and the **Franka Emika Panda manipulator**.

Run the following scripts to train and test the implemented environments with standard **DDPG** algorithm from **Stable Baselines**.

Here is a [introduction](https://github.com/robotology-playground/pybullet-robot-envs/blob/master/pybullet_robot_envs/README.md) of the robot env and task env.

How to train the robot using [baselines](https://github.com/eleramp/robot-agents).

- [gym-drake](https://github.com/HarvardAgileRoboticsLab/gym-drake)

Glue between [Drake](https://drake.mit.edu/) and OpenAI Gym. Including Kuka arm env.

Defines Drake Environments for use with OpenAI RL algorithms.

- [pytorch-rl](https://github.com/navneet-nmk/pytorch-rl)

This repository contains model-free deep reinforcement learning algorithms implemented in Pytorch. Using mujoco Fetch and Hand environments.

- [ur5 rl ros gazebo](https://github.com/hjalte33/rl_unscrew)

A reinforcement-Learning Framework for testing learning agents on a UR5 manipulator. The framework consists of 2 ROS packages which are rl_gazebo_sim, rl_moveit_config. Besides the two ROS packages there is the folder rl-gym with contains an OpenAI Gym environment as well as python scripts for runnin reinforcement learning. The rl-gym folder is an implementation example on how to use the framework with OpenAI Gym

The framework is designed and prepared for screwing tasks meanning the simulated UR5 is fitted with a screw tool and the world is fitted with a block with a screw.

- [visual_pushing_grsaping](https://github.com/andyzeng/visual-pushing-grasping)

Train robotic agents to learn to plan pushing and grasping actions for manipulation with deep reinforcement learning. http://vpg.cs.princeton.edu/

	- UR5 robot and two finger robotiq gripper
	- V-REP simulator
	- Intel RealSense D415 Camera
	- Calibrating Camera Extrinsics
	- UR5 python IK library
[ikfastpy](https://github.com/andyzeng/ikfastpy)

Python wrapper over OpenRave's IKFast inverse kinematics solver for a UR5 robot arm.


- [DAPG for Dexterous Hand Manipulation](https://github.com/aravindr93/hand_dapg)

Dexterous Hand Manipulation Reinforcement Learning Control Suite

It's a dexterous hand manipulation control suite, using mujoco simulator and gym RL environment.

[Project](https://sites.google.com/view/deeprl-dexterous-manipulation)

- [Efficient Exploration via State Marginal Matching](https://github.com/RLAgent/state-marginal-matching)

It just uses the default control task in gym mujoco FetchEnv and ManipulationEnv.

Mujoco 1.5


- [robotsuite](https://github.com/StanfordVL/robosuite)

Surreal Robitics Suite: standardized and accessible robot manipulation benchmark in physics simulation. http://surreal.stanford.edu

	- standardized tasks: a set of single-arm and bimanual manipulation tasks of large diversity and varying complexity.
	- procedural generation: modularized APIs for programmatically creating new scenes and new tasks as a combinations of robot models, arenas, and parameterized 3D objects;
	- controller modes: a selection of controller types to command the robots, such as joint velocity control, inverse kinematics control, and 3D motion devices for teleoperation;
	- multi-modal sensors: heterogeneous types of sensory signals, including low-level physical states, RGB cameras, depth maps, and proprioception;
	- human demonstrations: utilities for collecting human demonstrations, replaying demonstration datasets, and leveraging demonstration data for learning.


- [surreal](https://github.com/SurrealAI/Surreal)

Open-Source Distributed Reinforcement Learning Framework by Stanford Vision and Learning Lab https://surreal.stanford.edu

- [rllab-curriculum](https://github.com/florensacc/rllab-curriculum)

Curriculum learning

- [DoorGym](https://github.com/PSVL/DoorGym)

Open source domain randomized door opening training environment.

- [raisimGym](https://github.com/leggedrobotics/raisimGym)

raisimGym is an example of a gym environment using raisim. It uses stable-baselines (https://github.com/hill-a/stable-baselines) for training and pybind11 (https://github.com/pybind/pybind11) for wrapping raisim in python.

- [SpotmicroAI](https://github.com/FlorianWilk/SpotMicroAI)

The SpotMicroAI project is designed to be a low cost, easily built quadruped robot. The design is roughly based off of Boston Dynamics quadruped robot SpotMini, though with obvious adaptations such as size and sensor suite.

The project is maintained by a community of volunteers and is very much still in its early stages. Any individual is welcome to contribute, and in particular expertise in areas involving simulation, reinforcement learning, and hardware development is greatly appreciated.

All documentation and tutorials can be found at: [spotmicroai.readthedocs.io](https://github.com/FlorianWilk/SpotMicroAI/blob/master/spotmicroai.readthedocs.io)

- [dm_env](https://github.com/deepmind/dm_env)

A python interface for reinforcement learning environments.

- [SenseAct](https://github.com/kindredresearch/SenseAct)

SenseAct: A computational framework for developing real-world robot learning tasks https://www.kindred.ai/SenseAct

This repository provides the implementation of several reinforcement learning tasks with multiple real-world robots. These tasks come with an interface similar to OpenAI-Gym so that learning algorithms can be plugged in easily and in a uniform manner across tasks.  In this computational framework, agent and environment-related computations are ordered and distributed among multiple concurrent processes in a specific way. 

UR robotic arms

- [WalkingSpider_OpenAI_PyBullet_ROS](https://github.com/rubencg195/WalkingSpider_OpenAI_PyBullet)

- [DHER](https://github.com/mengf1/DHER)

here are dynamic goal environments. We modify the robotic manipulation environments created by OpenAI (Brockman et al., 2016) for our experiments.

DHER: Hindsight Experience Replay for Dynamic Goals (ICLR-2019) https://openreview.net/pdf?id=Byf5-30qFX

- [rlg](https://github.com/ashwinreddy/rlg)

[document](https://github.com/ashwinreddy/rlg/wiki)

Robot Learning Gym

## UR robot

- [python control ur](https://github.com/SintefManufacturing/python-urx)

Python library to control a robot from 'Universal Robots'.

- [ReinforcementLearning4Robot](https://github.com/HsiaoTsan/ReinforcementLearning4Robot)

Reinforcement learning algorithm HER implemented on UR5 robot to execute grasp and place task.

Using two finger robotiq gripper and [python_urx](https://github.com/SintefManufacturing/python-urx) to control the ur robot.

ros control

- [as_urrobotiq](https://github.com/ancorasir/as_urobotiq)

as_urrobotiq is inteded to be setup as a general purpose robot platform for autonomous pick-and-place with deep learning.

It use the UR5 arm, Robotiq 3 finger gripper, kinect, Xtion, FT300 sensor, Tensorflow.

- [as_DeepClaw](https://github.com/ancorasir/as_DeepClaw)

It's the same project with [as_urrobotiq](https://github.com/ancorasir/as_urobotiq).

The aim of this project is to explore autonomous and adaptive robotic pick-and-place through deep learning.

- [Robotiq-UR5](https://github.com/cxy1997/Robotiq-UR5)

Simulator of UR5 robotic arm with Robotiq 2 finger gripper, built with MuJoCo.

- [ur-ikfastpy](https://github.com/andyzeng/ikfastpy)

Python wrapper over OpenRave's IKFast inverse kinematics solver for a UR5 robot arm.

- [mujoco-ur5-model](https://github.com/roboticsleeds/mujoco_ur5_model)

Mujoco Model for UR5-Ridgeback-Robotiq Robot 

## ROS Gazebo

- [Robotics AI mobile manipulation](https://github.com/sudhakaranjain/Robotics_AI)

Implementation of various algorithms on domestic robot using ROS. Mobile manipulation, using kinova arm.

- [tiago-gym-gazebo](https://github.com/huiwenzhang/tiago-gym-gazebo)

A TIAGo environment used for manipulation tasks learning based on ros and openai gym

- [ur5 rl](https://github.com/hjalte33/rl_unscrew)

A reinforcement-Learning Framework for testing learning agents on a UR5 manipulator. The framework consists of 2 ROS packages which are rl_gazebo_sim, rl_moveit_config. Besides the two ROS packages there is the folder rl-gym with contains an OpenAI Gym environment as well as python scripts for runnin reinforcement learning. The rl-gym folder is an implementation example on how to use the framework with OpenAI Gym

The framework is designed and prepared for screwing tasks meanning the simulated UR5 is fitted with a screw tool and the world is fitted with a block with a screw.

- [Ur5_DRL](https://github.com/yuecideng/Ur5_DRL)

This is a project about robotic manipulation motion planning using deep reinforcement learning based on ROS and Gazebo simulation

- [AS_6Dof_Arm](https://github.com/yao62995/AS_6Dof_Arm)

robot arm by ROS & Moveit, Train Deep Reinforcement Algorithms

- [gym-sawyer](https://github.com/rlworkgroup/gym-sawyer)

Sawyer environments for reinforcement learning that use the OpenAI Gym interface, as well as Dockerfiles with ROS to communicate with the real robot or a simulated one with Gazebo.

- [navbot](https://github.com/marooncn/navbot)

Using RGB Image as Visual Input for Mapless Robot Navigation

[Project introduction](
https://mp.weixin.qq.com/s?__biz=Mzg2MjExNjY5Mg==&mid=2247483714&idx=1&sn=449c6c1b00272d31b9093e8ae32e5ca5&chksm=ce0d8f79f97a066fcc5929cdbd0fc83ce8412eaf9d97a5c51ed16799d7e8a401027dc3bb6486&mpshare=1&scene=1&srcid=&pass_ticket=9Mwfi8nrJduWesFYZOvfaN1uXqSrd%2B2CuQl%2FzqbUNmBAfv%2Bx%2BxgJyw8xSQfYkcsl#rd)

- [gym introduction](https://zhuanlan.zhihu.com/p/26985029)

- [HorizonRobotics-SocialRobot](https://github.com/HorizonRobotics/SocialRobot)

A python environment for developing interactive learning agent with language communication ability. Using **Gazebo** and **OpenAI gym**.

We provide OpenAI gym interfaces to easily apply different RL algorithms into these different environments. 

Robot: navigation, iCub, PR2. Using [Agent Learning Framework (ALF)](https://github.com/HorizonRobotics/alf) to train the model.

Agent Learning Framework (ALF) is a reinforcement learning framework emphasizing on the flexibility of writing complex model architectures. ALF is built on **Tensorflow 2.0**.

Algorithms: A2C, DDPG, PPO, SAC, ICM, MERLIN

## V-REP

- [RL demo](https://github.com/marooncn/RL)

mobile robot rl demo


# Reinforcement Learning Algorithms


- [OpenAI Baselines](https://github.com/openai/baselines)

OpenAI Baselines: high-quality implementations of reinforcement learning algorithms.

- [TF-Agents](https://github.com/tensorflow/agents)

TF-Agents: A library for reinforcement learning in tensorflow.

- [Stable Baselines](https://github.com/hill-a/stable-baselines)

A fork of OpenAI Baselines, implementations of reinforcement learning algorithms. http://stable-baselines.readthedocs.io/

- [robot-agents-train](https://github.com/eleramp/robot-agents)

Robot-agents is a Python toolkit to develop and test Reinforcement Learning algorithms on robotic **manipulation** tasks.

Including: 
  openai_baselines: ddpg
  stable_baselines: ddpg, deepq, sac

- [Coach](https://nervanasystems.github.io/coach/) (By Nervana Systems)

Coach, developed by Intel AI lab, is a python reinforcement learning framework containing implementation of many state-of-the-art algorithms.

- [Keras-RL](https://github.com/keras-rl/keras-rl)

Deep Reinforcement Learning for Keras. http://keras-rl.readthedocs.io/

- [tensorforce](https://github.com/tensorforce/tensorforce)

Tensorforce: a TensorFlow library for applied reinforcment learning

- [tensorlayer](https://github.com/tensorlayer/tensorlayer)

Deep Learning and Reinforcement Learning Library for Scientists http://tensorlayer.readthedocs.io

- [softlearning](https://github.com/rail-berkeley/softlearning)

Softlearning is a reinforcement learning framework for training maximum entropy policies in continuous domains. Includes the official implementation of the Soft Actor-Critic algorithm. https://sites.google.com/view/sac-and-applications

- [rlkit](https://github.com/vitchyr/rlkit)

Collection of reinforcement learning algorithms.

Reinforcement learning framework and algorithms implemented in **PyTorch**.

- [rlpyt](https://github.com/astooke/rlpyt)

Deep Reinforcement Learning in PyTorch
Modular, optimized implementations of common deep RL algorithms in PyTorch, with unified infrastructure supporting all three major families: policy gradient, deep-q learning, and q-function policy gradient. Intended to be a high-throughput code-base for small- to medium-scale research (large-scale meaning like OpenAI Dota with 100's GPUs). 

- [Chainer-rl](https://github.com/chainer/chainerrl)

hainerRL is a deep reinforcement learning library that implements various state-of-the-art deep reinforcement algorithms in Python using [Chainer](https://github.com/chainer/chainer), a flexible deep learning framework.

- [chainerrl-mujoco-tasks](https://github.com/chainer/chainerrl/tree/master/examples/mujoco)

Using chainerrl to train the rl model in mujoco simulation.

- [Minimal and Clean RL Examples](https://github.com/rlcode/reinforcement-learning)

Minimal and clean examples of reinforcement learning algorithms presented by RLCode team

- [drl-tensorflow-implement](https://github.com/carpedm20/deep-rl-tensorflow)

TensorFlow implementation of Deep Reinforcement Learning papers

- [reinforcement-learning-an-introduction code](https://github.com/ShangtongZhang/reinforcement-learning-an-introduction)

Python replication for Sutton & Barto's book [Reinforcement Learning: An Introduction (2nd Edition)](http://incompleteideas.net/book/the-book-2nd.html)


- [Interpolated-Policy-Gradient-with-PPO-for-Robotics-Control](https://github.com/jianing-sun/Interpolated-Policy-Gradient-with-PPO-for-Robotics-Control-)

Some Results based on FetchReach-v0 environment between IPG and PPO:
A slide for initial result and comparison among PPO, IPG and HER+IPG based on multi-goal RL environment (FetchReach-v0 from Robotic of Gym).

- [Prioritized Experience Replay (PER)](https://github.com/rlcode/per)

PER(Prioritized Experience Replay) implementation in PyTorch

- [Hierarchical Meta Reinforcement Learning](https://github.com/navneet-nmk/Hierarchical-Meta-Reinforcement-Learning)

This repository contains the implementation for the paper - Exploration via Hierarchical Meta Reinforcement Learning.

- [pytorch-maml-rl](https://github.com/tristandeleu/pytorch-maml-rl)

Reinforcement Learning with Model-Agnostic Meta-Learning in Pytorch

- [maml-rl](https://github.com/cbfinn/maml_rl/)

Code for RL experiments in "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"

- [maml](https://github.com/cbfinn/maml)

Code for "Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks"

- [reinforcement implementation](https://github.com/zhangchuheng123/Reinforcement-Implementation)

This project aims to reproduce the results of several model-free RL algorithms in continuous action domain (mujuco environment).

This projects

1. uses pytorch package
2. implements different algorithms independently in seperate files
3. is written in simplest style
4. tries to follow the original paper and reproduce their results

- [ddpg](https://github.com/pemami4911/deep-rl)

- [autoregressive policies (ARPs)](https://github.com/kindredresearch/arp)

This repository provides the implementation of autoregressive policies (ARPs) for continuous control deep reinforcement learning together with learning examples based on Open AI Baselines PPO and TRPO algorithms. The examples are provided for OpenAI Gym Mujoco environments and for Square sparse reward environment, discussed in the paper.

Using UR5 

- [udacity-drl](https://github.com/udacity/deep-reinforcement-learning)

Deep Reinforcement Learning Nanodegree program https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893#

- [for-ai-rl](https://github.com/for-ai/rl)

Generic reinforcement learning codebase in TensorFlow



# Reinforcement Learning Resources


- [OpenAI SpinningUp](https://spinningup.openai.com/)

An educational resource to help anyone learn deep reinforcement learning.



# Sim2Real Problems

How to transfer a model from simulation to the real robot

## ROS Related

For now, most robots can be controlled using ROS. So how to using the reinforcement learning algorithms in ROS is a solution for sim2real.

### Training in ROS



#### Reinforcement Learning in ROS

[reinforcement learning](http://wiki.ros.org/reinforcement_learning)



#### OpenAI ROS

Developed by xxx, the useful tool to use RL in ROS.


## RL tools

### Visualization

- [chainerrl-visualizer](https://github.com/chainer/chainerrl-visualizer)

You can analyze ChainerRL agent's behavior in well visualized way, making debugging easier.

